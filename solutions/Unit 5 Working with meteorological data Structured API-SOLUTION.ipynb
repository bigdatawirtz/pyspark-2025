{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with meteorological data  - Structured API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use meteorological data from Meteogalicia that contains the measurements of a weather station in Santiago during June 2017.\n",
    "\n",
    "The objective is to **calculate the average temperature per day**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('datasets/meteogalicia.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------+\n",
      "|_c0                                                                                    |\n",
      "+---------------------------------------------------------------------------------------+\n",
      "|ESTACI�N AUTOM�TICA:Santiago-EOAS                                                      |\n",
      "|CONCELLO:Santiago de Compostela                                                        |\n",
      "|PROVINCIA:A Coru�a                                                                     |\n",
      "|C�DIGOS DE VALIDACI�N DOS DATOS:                                                       |\n",
      "|0:  Dato sen validar                                                                   |\n",
      "|1:  Dato v�lido orixinal                                                               |\n",
      "|2:  Dato sospeitoso                                                                    |\n",
      "|3:  Dato err�neo                                                                       |\n",
      "|4:  Dato acumulado                                                                     |\n",
      "|5:  Dato v�lido interpolado                                                            |\n",
      "|9:  Dato non rexistrado                                                                |\n",
      "|Nota: O valor -9999 indicar� dato non rexistrado                                       |\n",
      "|Tipo de consulta: Variables dez-minutais                                               |\n",
      "|Per�odo:1/6/2017-30/6/2017                                                             |\n",
      "|COD.VALIDACI�N  DATA (Horario UTC)       Par�metro (Unidades)                     Valor|\n",
      "|      1          2017-06-01 00:10:00    Temperatura media (�C)                    13   |\n",
      "|      1          2017-06-01 00:20:00    Temperatura media (�C)                    13   |\n",
      "|      1          2017-06-01 00:30:00    Temperatura media (�C)                    13   |\n",
      "|      1          2017-06-01 00:40:00    Temperatura media (�C)                    13   |\n",
      "|      1          2017-06-01 00:50:00    Temperatura media (�C)                    13   |\n",
      "+---------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(20, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'',\n",
       " u'      1          2017-06-01 00:10:00    Temperatura media (\\ufffdC)                    13,82',\n",
       " u'      1          2017-06-01 00:20:00    Temperatura media (\\ufffdC)                    13,71',\n",
       " u'      1          2017-06-01 00:30:00    Temperatura media (\\ufffdC)                    13,61',\n",
       " u'      1          2017-06-01 00:40:00    Temperatura media (\\ufffdC)                    13,52']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read as RDD, skip 20 rows, then apply schema\n",
    "rdd = spark.sparkContext.textFile(\"datasets/meteogalicia.txt\")\n",
    "rdd_skipped = rdd.zipWithIndex().filter(lambda x: x[1] >= 22).map(lambda x: x[0])\n",
    "\n",
    "rdd_skipped.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'2017-06-01', 13.82),\n",
       " (u'2017-06-01', 13.71),\n",
       " (u'2017-06-01', 13.61),\n",
       " (u'2017-06-01', 13.52),\n",
       " (u'2017-06-01', 13.33)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperatures = rdd.filter(lambda line: 'Temperatura media' in line) \\\n",
    "    .map(lambda line: (line.split()[1], float(line.split()[6].replace(',','.'))   ))\n",
    "temperatures.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|      data|valor|\n",
      "+----------+-----+\n",
      "|2017-06-01|13.82|\n",
      "|2017-06-01|13.71|\n",
      "|2017-06-01|13.61|\n",
      "|2017-06-01|13.52|\n",
      "|2017-06-01|13.33|\n",
      "+----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"data\", StringType(), True),\n",
    "    StructField(\"valor\", DoubleType(), True)\n",
    "])\n",
    "\n",
    "df_temp = spark.createDataFrame(temperatures,schema=schema)\n",
    "df_temp.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the average temperature per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+\n",
      "|      data|        avg(valor)|\n",
      "+----------+------------------+\n",
      "|2017-06-22| 19.56493055555555|\n",
      "|2017-06-07| 17.76305555555556|\n",
      "|2017-06-24|           17.6775|\n",
      "|2017-06-29|13.477083333333331|\n",
      "|2017-06-19|25.422708333333333|\n",
      "|2017-06-03|14.511736111111105|\n",
      "|2017-06-23| 18.57861111111111|\n",
      "|2017-06-28|15.242361111111105|\n",
      "|2017-06-12|20.020138888888884|\n",
      "|2017-06-30|             11.59|\n",
      "|2017-06-26|18.298125000000002|\n",
      "|2017-06-04|14.889375000000005|\n",
      "|2017-06-18|26.350069444444443|\n",
      "|2017-06-06|14.901041666666666|\n",
      "|2017-06-09| 17.86694444444445|\n",
      "|2017-06-21| 23.28430555555555|\n",
      "|2017-06-25| 19.57138888888889|\n",
      "|2017-06-14| -51.6271527777778|\n",
      "|2017-06-16|22.042708333333337|\n",
      "|2017-06-11|17.806250000000006|\n",
      "+----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_temp.groupBy('data').avg('valor').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the results sorted by date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+\n",
      "|      data|        avg(valor)|\n",
      "+----------+------------------+\n",
      "|2017-06-01|17.179580419580425|\n",
      "|2017-06-02|16.007500000000004|\n",
      "|2017-06-03|14.511736111111105|\n",
      "|2017-06-04|14.889375000000005|\n",
      "|2017-06-05| 13.67486111111111|\n",
      "|2017-06-06|14.901041666666666|\n",
      "|2017-06-07| 17.76305555555556|\n",
      "|2017-06-08| 17.49979166666667|\n",
      "|2017-06-09| 17.86694444444445|\n",
      "|2017-06-10|19.207222222222224|\n",
      "|2017-06-11|17.806250000000006|\n",
      "|2017-06-12|20.020138888888884|\n",
      "|2017-06-13|18.769027777777776|\n",
      "|2017-06-14| -51.6271527777778|\n",
      "|2017-06-15|18.135486111111103|\n",
      "|2017-06-16|22.042708333333337|\n",
      "|2017-06-17|25.475902777777772|\n",
      "|2017-06-18|26.350069444444443|\n",
      "|2017-06-19|25.422708333333333|\n",
      "|2017-06-20|26.977916666666665|\n",
      "+----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_temp.groupBy('data').avg('valor').orderBy('data').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
